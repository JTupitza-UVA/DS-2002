{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "209e78d4-6dc7-4719-b542-88ba738bef17",
   "metadata": {},
   "source": [
    "## Demo: Medallion Architecture Using Parquet Files and Queried with the PySpark SQL API\n",
    "### Overview\n",
    "Structured Streaming is a scalable and fault-tolerant stream processing engine built on the Spark SQL engine. You can express your streaming computation the same way you would express a batch computation on static data. The Spark SQL engine will take care of running it incrementally and continuously and updating the final result as streaming data continues to arrive. You can use the Dataset/DataFrame API in Scala, Java, Python or R to express streaming aggregations, event-time windows, stream-to-batch joins, etc. The computation is executed on the same optimized Spark SQL engine. Finally, the system ensures end-to-end exactly-once fault-tolerance guarantees through checkpointing and Write-Ahead Logs. In short, Structured Streaming provides fast, scalable, fault-tolerant, end-to-end exactly-once stream processing without the user having to reason about streaming.\n",
    "\n",
    "Internally, by default, Structured Streaming queries are processed using a micro-batch processing engine, which processes data streams as a series of small batch jobs thereby achieving end-to-end latencies as low as 100 milliseconds and exactly-once fault-tolerance guarantees. However, since Spark 2.3, we have introduced a new low-latency processing mode called Continuous Processing, which can achieve end-to-end latencies as low as 1 millisecond with at-least-once guarantees. Without changing the Dataset/DataFrame operations in your queries, you will be able to choose the mode based on your application requirements.\n",
    "\n",
    "### Lab Details:\n",
    "\n",
    "This lab will demonstrate ingesting artificially generated medical data, in JSON format, that simulates heart rate monitor signals captured from numerous devices; therefore, this data represents what would be expected from a Streaming data source.\n",
    "\n",
    "#### Datasets Used:\n",
    "The schema of our two datasets is represented below. Note that we will be manipulating these schema during various steps.\n",
    "\n",
    "##### Recordings:\n",
    "The main dataset uses heart rate recordings from medical devices delivered in the JSON format.\n",
    "\n",
    "| Field | Type |\n",
    "| --- | --- |\n",
    "| device_id | int |\n",
    "| mrn | long |\n",
    "| time | double |\n",
    "| heartrate | double |\n",
    "\n",
    "##### Personally Identifiable Information (PII):\n",
    "These data will later be joined with a static table of patient information stored in an external system to identify patients.\n",
    "\n",
    "| Field | Type |\n",
    "| --- | --- |\n",
    "| mrn | long |\n",
    "| name | string |\n",
    "\n",
    "### Prerequisites:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af67835d-0dd5-461c-9f66-ad60bc27ff74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\spark-3.5.4-bin-hadoop3'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "findspark.find()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63b270a6-c516-4e23-8b99-2575f3880165",
   "metadata": {},
   "source": [
    "#### Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2254708f-fdba-42af-ae1f-add9b66b07a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import time\n",
    "\n",
    "from pyspark import SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd6732d0-0f54-4d36-b205-1cc4d2ad831b",
   "metadata": {},
   "source": [
    "#### Instantiate Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1450fbb2-eb89-470e-89e9-c69218446ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------------------------------------\n",
    "# Specify Directory Structure for Source Data\n",
    "# --------------------------------------------------------------------------------\n",
    "base_dir = os.path.join(os.getcwd(), 'lab_data')\n",
    "data_dir = os.path.join(base_dir, 'healthcare')\n",
    "batch_dir = os.path.join(data_dir, 'batch')\n",
    "stream_dir = os.path.join(data_dir, 'streaming')\n",
    "tracker_stream_dir = os.path.join(stream_dir, 'tracker')\n",
    "\n",
    "# --------------------------------------------------------------------------------\n",
    "# Create Directory Structure for Data Lakehouse Files\n",
    "# --------------------------------------------------------------------------------\n",
    "dest_database = \"healthcare_dlh\"\n",
    "sql_warehouse_dir = os.path.abspath('spark-warehouse')\n",
    "database_dir = os.path.join(sql_warehouse_dir, dest_database)\n",
    "\n",
    "patient_output_bronze = os.path.join(database_dir, 'dim_patient')\n",
    "heartbeat_output_bronze = os.path.join(database_dir, 'fact_heartbeat_bronze')\n",
    "heartbeat_output_silver = os.path.join(database_dir, 'fact_heartbeat_silver')\n",
    "heartbeat_output_gold = os.path.join(database_dir, 'fact_heartbeat_gold')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4695da09-b727-4763-b75d-a5ec4c9da951",
   "metadata": {},
   "source": [
    "#### Create a New Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0b9db63-a330-4e9c-897f-40765e5d0724",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://JT-5570:4041\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.4</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[10]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySpark Heartrate Monitor in Juptyer</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x223161e41a0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "worker_threads = f\"local[{int(os.cpu_count()/2)}]\"\n",
    "shuffle_partitions = int(os.cpu_count())\n",
    "\n",
    "sparkConf = SparkConf().setAppName('PySpark Heartrate Monitor in Juptyer')\\\n",
    "    .setMaster(worker_threads)\\\n",
    "    .set('spark.driver.memory', '2g') \\\n",
    "    .set('spark.executor.memory', '3g')\\\n",
    "    .set(\"spark.sql.adaptive.enabled\", 'false') \\\n",
    "    .set('spark.sql.shuffle.partitions', shuffle_partitions) \\\n",
    "    .set('spark.sql.streaming.forceDeleteTempCheckpointLocation', 'true') \\\n",
    "    .set('spark.sql.streaming.schemaInference', 'true') \\\n",
    "    .set('spark.sql.warehouse.dir', database_dir) \\\n",
    "    .set('spark.streaming.stopGracefullyOnShutdown', 'true')\n",
    "\n",
    "spark = SparkSession.builder.config(conf=sparkConf).getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7b55ad1-194e-4796-bdcc-dc1b00a99336",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "### Create Bronze Layer\n",
    "#### Read a Batch of Patient dimension data from a CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2c1ef5f-f581-42c7-8520-1dd980df764b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jtupi\\Documents\\UVA\\DS-2002-Teacher\\04-PySpark\\lab_data\\healthcare\\batch\\patient_info.csv\n"
     ]
    }
   ],
   "source": [
    "patient_csv = os.path.join(batch_dir, 'patient_info.csv')\n",
    "\n",
    "# Unit Test\n",
    "print(patient_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d4d740c9-d6de-4229-86a0-9b44390884fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- mrn: integer (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      "\n",
      "The 'df_patients' table contains 34 rows.\n",
      "+--------+---------------+\n",
      "|     mrn|           name|\n",
      "+--------+---------------+\n",
      "|23940128| Caitlin Garcia|\n",
      "|18064290|  Anthony Perez|\n",
      "|95384990|     Tanya Diaz|\n",
      "|53057176|Autumn Calderon|\n",
      "|96005424|   Ronald Smith|\n",
      "+--------+---------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_patient = spark.read.format('csv').options(header='true', inferSchema=True).load(patient_csv)\n",
    "\n",
    "# Unit Test -------------\n",
    "df_patient.printSchema()\n",
    "print(f\"The 'df_patients' table contains {df_patient.count()} rows.\")\n",
    "df_patient.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a1e8d3c-823e-4339-ac75-871f688ab1dc",
   "metadata": {},
   "source": [
    "#### Persist the Patient dimension data to a Parquet file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e391257d-e7eb-44d5-a879-af0c97bbc8d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_patient.write.mode(\"overwrite\").parquet(patient_output_bronze)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "db8e4871-dda4-4f70-b186-fc04838ac11d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------------+\n",
      "|     mrn|           name|\n",
      "+--------+---------------+\n",
      "|23940128| Caitlin Garcia|\n",
      "|18064290|  Anthony Perez|\n",
      "|95384990|     Tanya Diaz|\n",
      "|53057176|Autumn Calderon|\n",
      "|96005424|   Ronald Smith|\n",
      "+--------+---------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Unit Test -------------------------------------------\n",
    "df_patient = spark.read.parquet(patient_output_bronze)\n",
    "df_patient.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e49c8e-4c34-4c5d-89d9-6f0ed8deec02",
   "metadata": {},
   "source": [
    "#### Use Structured Streaming to Read Heartrate Monitor data\n",
    "##### Read data from a series of JSON source files into a streaming DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4b75f7db-aabe-404e-a558-6d0921e8cfa1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tracker = (spark.readStream \\\n",
    "              .option(\"schemaLocation\", heartbeat_output_bronze) \\\n",
    "              .option(\"maxFilesPerTrigger\", 1) \\\n",
    "              .option(\"multiLine\", \"true\") \\\n",
    "              .json(tracker_stream_dir)\n",
    "             )\n",
    "\n",
    "df_tracker.isStreaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a626f964-9fc1-4eb1-bbde-fa1adc644968",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pyspark.sql.dataframe.DataFrame'>\n",
      "root\n",
      " |-- device_id: string (nullable = true)\n",
      " |-- heartrate: string (nullable = true)\n",
      " |-- mrn: string (nullable = true)\n",
      " |-- time: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Unit Test -------------\n",
    "print(type(df_tracker))\n",
    "df_tracker.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dabadb8-9f56-416a-8d83-404a14a2a30f",
   "metadata": {},
   "source": [
    "#### Write data from streaming DataFrame into a Parquet output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "469ab7ae-400d-4684-bb59-0ec6e3d84589",
   "metadata": {},
   "outputs": [],
   "source": [
    "tracker_checkpoint_bronze = os.path.join(heartbeat_output_bronze, '_checkpoint')\n",
    "\n",
    "bronze_query = (df_tracker.writeStream \\\n",
    "                .format(\"parquet\") \\\n",
    "                .outputMode(\"append\") \\\n",
    "                .queryName(\"heartbeat_tracker_bronze\")\n",
    "                .trigger(availableNow = True) \\\n",
    "                .option(\"checkpointLocation\", tracker_checkpoint_bronze) \\\n",
    "                .option(\"compression\", \"snappy\") \\\n",
    "                .start(heartbeat_output_bronze)\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "28498f0c-bfc0-49de-aa00-0a0fb676a143",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query ID: 97eb5ffd-02c0-4c23-b942-af6add401d8f\n",
      "Query Name: heartbeat_tracker_bronze\n",
      "Query Status: {'message': 'Writing offsets to log', 'isDataAvailable': True, 'isTriggerActive': True}\n",
      "Last Progress: {'id': '97eb5ffd-02c0-4c23-b942-af6add401d8f', 'runId': '61097a09-bf03-4ee8-8602-7e89dadb100f', 'name': 'heartbeat_tracker_bronze', 'timestamp': '2025-03-17T17:24:46.594Z', 'batchId': 3, 'numInputRows': 10000, 'inputRowsPerSecond': 10172.93997965412, 'processedRowsPerSecond': 10449.320794148382, 'durationMs': {'addBatch': 378, 'commitOffsets': 177, 'getBatch': 15, 'latestOffset': 177, 'queryPlanning': 8, 'triggerExecution': 957, 'walCommit': 197}, 'stateOperators': [], 'sources': [{'description': 'FileStreamSource[file:/C:/Users/jtupi/Documents/UVA/DS-2002-Teacher/04-PySpark/lab_data/healthcare/streaming/tracker]', 'startOffset': {'logOffset': 2}, 'endOffset': {'logOffset': 3}, 'latestOffset': None, 'numInputRows': 10000, 'inputRowsPerSecond': 10172.93997965412, 'processedRowsPerSecond': 10449.320794148382}], 'sink': {'description': 'FileSink[C:\\\\Users\\\\jtupi\\\\Documents\\\\UVA\\\\DS-2002-Teacher\\\\04-PySpark\\\\spark-warehouse\\\\healthcare_dlh\\\\fact_heartbeat_bronze]', 'numOutputRows': -1}}\n"
     ]
    }
   ],
   "source": [
    "# Unit Test ----------------------------------\n",
    "print(f\"Query ID: {bronze_query.id}\")\n",
    "print(f\"Query Name: {bronze_query.name}\")\n",
    "print(f\"Query Status: {bronze_query.status}\")\n",
    "print(f\"Last Progress: {bronze_query.lastProgress}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0ff79c4a-d9df-4863-85b2-aff008b07d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "bronze_query.awaitTermination()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89bbe9b7-c5b3-4450-803f-291fcb6449b6",
   "metadata": {},
   "source": [
    "### Create Silver Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70064bd9-f881-4549-9700-545cf2534195",
   "metadata": {},
   "source": [
    "#### Define Silver Query to Join Streaming with Batch Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "57ef3f36-cea0-48bc-8c32-3f6cc0d3eb0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_silver = spark.readStream.format(\"parquet\").load(heartbeat_output_bronze) \\\n",
    "    .join(df_patient, \"mrn\") \\\n",
    "    .select(col(\"device_id\").cast(IntegerType()), \\\n",
    "            col(\"mrn\").cast(LongType()), \\\n",
    "            (col(\"time\")/1e6).cast(TimestampType()).alias(\"datetime\"), \\\n",
    "            col(\"heartrate\").cast(DoubleType()), \\\n",
    "            col(\"name\").alias(\"patient_name\")\n",
    "           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4a80c45b-71ae-4f41-9493-4eb4ae40c615",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- device_id: integer (nullable = true)\n",
      " |-- mrn: long (nullable = true)\n",
      " |-- datetime: timestamp (nullable = true)\n",
      " |-- heartrate: double (nullable = true)\n",
      " |-- patient_name: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Unit Test -----------\n",
    "df_silver.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40bf5bff-3d78-43c4-aa62-cfe56dbc2357",
   "metadata": {},
   "source": [
    "#### Persist Data to a Parquet file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a8d425ce-63ac-446c-8dc6-1ce7d133069f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tracker_checkpoint_silver = os.path.join(heartbeat_output_silver, '_checkpoint')\n",
    "\n",
    "silver_query = (df_silver.writeStream \\\n",
    "                .format(\"parquet\") \\\n",
    "                .outputMode(\"append\") \\\n",
    "                .queryName(\"heartbeat_tracker_silver\")\n",
    "                .trigger(availableNow = True) \\\n",
    "                .option(\"checkpointLocation\", tracker_checkpoint_silver) \\\n",
    "                .option(\"compression\", \"snappy\") \\\n",
    "                .start(heartbeat_output_silver)\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "66b27cbe-6dd6-438f-9f18-41b593206cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unit Test -------------------------------------------\n",
    "silver_query.awaitTermination()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6ab1f48-0275-488d-8dfa-de4f9065decf",
   "metadata": {},
   "source": [
    "### Create Gold Layer\n",
    "##### Define Gold Query to Perform an Aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4edc0481-c30f-47a1-b621-1cdd6d8360c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_heartrate_by_patient_gold = spark.readStream.format(\"parquet\").load(heartbeat_output_silver) \\\n",
    "    .groupBy('patient_name') \\\n",
    "    .agg((ceiling(avg(\"heartrate\")).alias(\"avg_heartrate\")), \\\n",
    "        (count(\"device_id\").alias(\"count\"))) \\\n",
    "    .orderBy(desc(\"avg_heartrate\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1c96d533-bbb6-4640-ae82-aaa4e41ecdf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- patient_name: string (nullable = true)\n",
      " |-- avg_heartrate: long (nullable = true)\n",
      " |-- count: long (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Unit Test -----\n",
    "df_heartrate_by_patient_gold.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a98a6689-7277-46e3-ac86-1f2518643d44",
   "metadata": {},
   "source": [
    "#### Persist Gold Data to a Parquet file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "730bccb7-1a7f-4f94-8a3e-d331753d3a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_query = (df_heartrate_by_patient_gold.writeStream \\\n",
    "              .outputMode(\"complete\") \\\n",
    "              .queryName(\"fact_heartbeat_by_patient_gold\") \\\n",
    "              .format(\"memory\")\n",
    "              .start()\n",
    "             )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35262c91-2e04-40d6-8246-a4f4ba8102ec",
   "metadata": {},
   "source": [
    "##### Read Gold Streaming Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f7f23127-029f-4698-9199-f151e71cb124",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fact_heartbeat_by_patient_gold = spark.sql(\"SELECT * FROM fact_heartbeat_by_patient_gold\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "40afc6ce-1235-4cde-9839-c5c7f9dcb62a",
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba9e89b-7470-4e50-bcb5-65313109e870",
   "metadata": {},
   "source": [
    "##### Display the Gold table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4c902220-2af2-4eb7-b6e2-7a913732b389",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_name</th>\n",
       "      <th>avg_heartrate</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>William Gomez Jr.</td>\n",
       "      <td>104</td>\n",
       "      <td>1069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Robert Vincent</td>\n",
       "      <td>100</td>\n",
       "      <td>3171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sean Brown</td>\n",
       "      <td>93</td>\n",
       "      <td>3354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mary Adams</td>\n",
       "      <td>93</td>\n",
       "      <td>3801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tanya Diaz</td>\n",
       "      <td>92</td>\n",
       "      <td>2153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Kyle Cruz</td>\n",
       "      <td>91</td>\n",
       "      <td>2822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>George King</td>\n",
       "      <td>90</td>\n",
       "      <td>3740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Sharon Brewer</td>\n",
       "      <td>86</td>\n",
       "      <td>1819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Rachel Contreras</td>\n",
       "      <td>86</td>\n",
       "      <td>4423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Valerie Reese</td>\n",
       "      <td>86</td>\n",
       "      <td>4326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Michelle Carter</td>\n",
       "      <td>85</td>\n",
       "      <td>3514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Nicholas Spears</td>\n",
       "      <td>85</td>\n",
       "      <td>3134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>John Estes</td>\n",
       "      <td>85</td>\n",
       "      <td>3264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Mark Harris</td>\n",
       "      <td>84</td>\n",
       "      <td>3717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Joshua Perkins</td>\n",
       "      <td>83</td>\n",
       "      <td>3484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Valerie Garcia</td>\n",
       "      <td>83</td>\n",
       "      <td>2726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Samuel Hughes</td>\n",
       "      <td>83</td>\n",
       "      <td>4138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Michael Maxwell</td>\n",
       "      <td>82</td>\n",
       "      <td>4446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>George Wagner</td>\n",
       "      <td>81</td>\n",
       "      <td>685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Caitlin Garcia</td>\n",
       "      <td>80</td>\n",
       "      <td>3322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Gabriela Gibson</td>\n",
       "      <td>80</td>\n",
       "      <td>3280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Sarah Kennedy</td>\n",
       "      <td>80</td>\n",
       "      <td>4661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Ashley Schmidt</td>\n",
       "      <td>79</td>\n",
       "      <td>3234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Lynn Russell</td>\n",
       "      <td>79</td>\n",
       "      <td>3716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Ronald Smith</td>\n",
       "      <td>79</td>\n",
       "      <td>2942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Joshua Harris</td>\n",
       "      <td>78</td>\n",
       "      <td>3381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Cynthia Figueroa</td>\n",
       "      <td>76</td>\n",
       "      <td>1409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Anthony Perez</td>\n",
       "      <td>75</td>\n",
       "      <td>2850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Dr. Amanda Baxter</td>\n",
       "      <td>75</td>\n",
       "      <td>4640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Melissa Martinez</td>\n",
       "      <td>75</td>\n",
       "      <td>2487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Crystal Ho</td>\n",
       "      <td>75</td>\n",
       "      <td>2973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Autumn Calderon</td>\n",
       "      <td>75</td>\n",
       "      <td>1819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Troy Davis</td>\n",
       "      <td>70</td>\n",
       "      <td>3463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>John Smith</td>\n",
       "      <td>69</td>\n",
       "      <td>2962</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         patient_name  avg_heartrate  count\n",
       "0   William Gomez Jr.            104   1069\n",
       "1      Robert Vincent            100   3171\n",
       "2          Sean Brown             93   3354\n",
       "3          Mary Adams             93   3801\n",
       "4          Tanya Diaz             92   2153\n",
       "5           Kyle Cruz             91   2822\n",
       "6         George King             90   3740\n",
       "7       Sharon Brewer             86   1819\n",
       "8    Rachel Contreras             86   4423\n",
       "9       Valerie Reese             86   4326\n",
       "10    Michelle Carter             85   3514\n",
       "11    Nicholas Spears             85   3134\n",
       "12         John Estes             85   3264\n",
       "13        Mark Harris             84   3717\n",
       "14     Joshua Perkins             83   3484\n",
       "15     Valerie Garcia             83   2726\n",
       "16      Samuel Hughes             83   4138\n",
       "17    Michael Maxwell             82   4446\n",
       "18      George Wagner             81    685\n",
       "19     Caitlin Garcia             80   3322\n",
       "20    Gabriela Gibson             80   3280\n",
       "21      Sarah Kennedy             80   4661\n",
       "22     Ashley Schmidt             79   3234\n",
       "23       Lynn Russell             79   3716\n",
       "24       Ronald Smith             79   2942\n",
       "25      Joshua Harris             78   3381\n",
       "26   Cynthia Figueroa             76   1409\n",
       "27      Anthony Perez             75   2850\n",
       "28  Dr. Amanda Baxter             75   4640\n",
       "29   Melissa Martinez             75   2487\n",
       "30         Crystal Ho             75   2973\n",
       "31    Autumn Calderon             75   1819\n",
       "32         Troy Davis             70   3463\n",
       "33         John Smith             69   2962"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fact_heartbeat_by_patient_gold \\\n",
    "    .select(\"patient_name\", \"avg_heartrate\", \"count\").toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "32813a55-21b4-4f35-b33a-c62b27f96503",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (3.12-env)",
   "language": "python",
   "name": "3.12-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
