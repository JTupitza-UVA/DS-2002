{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90be20ec-9272-47f7-aaa4-494d6dec66c5",
   "metadata": {},
   "source": [
    "## Using Python and Pandas Dataframes to Perform a MERGE (UPSERT) Operation\n",
    "When managing a data warehouse stored in a relational database management system (RDBMS) like Oracle, SQL Server, PostgreSQL or MySQL, a common requirement is to perform incremental updates of the dimension tables. When managing slowly-changing dimension (SCD) Type 1 changes, it is necessary to INSERT any new rows identified in the source database table(s) while UPDATING any existing rows where changes (updates) have been detected in the source database table(s).\n",
    "\n",
    "In this lab you will be refreshing the **Northwind_DW2** dimensional database you created earlier in Lab 3 using one of the most popular methods: the intrinsic capacity of the **Pandas Dataframes** to **Insert** new data and **Update** existing data.\n",
    "\n",
    "### 1.0. Prerequisites:\n",
    "This notebook uses the SqlAlchemy database connectivity library to connect to MySQL databases; therefore, if you have not already done so, you must have first installed that libary into your python environment by executing the following command in a Terminal window.\n",
    "\n",
    "- `python -m pip install sqlalchemy`\n",
    "\n",
    "#### 1.1. Import the Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e6ffbb8-08a3-4fc4-afb3-4f62fea4e2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy\n",
    "import pandas as pd\n",
    "import sqlalchemy\n",
    "from sqlalchemy import create_engine, text\n",
    "\n",
    "print(f\"Running SQL Alchemy Version: {sqlalchemy.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9def0f4-b7b1-4c9e-9119-06980a434f68",
   "metadata": {},
   "source": [
    "#### 1.2. Declare & Assign Connection Variables for the MySQL Server & Databases with which You'll be Working "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e8b1b96-5ccf-41de-a93a-f5d48fb40e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "host_name = \"localhost\"  #\"jtupitz-mysql.mysql.database.azure.com\"\n",
    "port = \"3306\"\n",
    "user_id = \"jtupitza\"\n",
    "pwd = \"Passw0rd123\"\n",
    "\n",
    "src_dbname = \"northwind\"\n",
    "dst_dbname = \"northwind_dw2\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb47b4b6-6fb6-4241-beac-19e46aedaadf",
   "metadata": {},
   "source": [
    "#### 1.3. Define Functions for Getting Data From and Setting Data Into Databases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ebf1a0-01d5-4a71-b98c-20f92e6582c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mysql_connection(user_id, pwd, host_name, db_name):\n",
    "    '''Create a connection to the MySQL database'''\n",
    "    conn_str = f\"mysql+pymysql://{user_id}:{pwd}@{host_name}/{db_name}\"\n",
    "    sqlEngine = create_engine(conn_str, pool_recycle=3600)\n",
    "    connection = sqlEngine.connect()\n",
    "\n",
    "    return connection\n",
    "    \n",
    "\n",
    "def get_dataframe(db_connection, sql_query):\n",
    "    dframe = pd.read_sql(text(sql_query), db_connection);\n",
    "    db_connection.close()\n",
    "    \n",
    "    return dframe\n",
    "\n",
    "\n",
    "def set_dataframe(db_connection, df, table_name, pk_column, db_operation):\n",
    "    try:\n",
    "        if db_operation in ['insert', 'update']:\n",
    "            if db_operation.lower() == \"insert\":\n",
    "                df.to_sql(table_name, con=db_connection, index=False, if_exists='replace')\n",
    "                db_connection.execute(text(f\"ALTER TABLE {table_name} ADD {pk_column} INT AUTO_INCREMENT PRIMARY KEY FIRST;\"))\n",
    "                    \n",
    "            elif db_operation.lower() == \"update\":\n",
    "                df.to_sql(table_name, con=db_connection, index=False, if_exists='append')\n",
    "\n",
    "        else:\n",
    "            print(\"The value supplied to the 'db_operation' parameter must be either 'insert' or 'update'.\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        return f\"An error occured: {e}\"\n",
    "        \n",
    "    db_connection.close()\n",
    "\n",
    "\n",
    "def upsert_dataframes(source_df, source_key, target_df, target_key, columns):\n",
    "    '''Perform a MERGE (Upsert) operation using Pandas Dataframes.'''\n",
    "    # 1. Set the index for both DataFrames to their common business-key\n",
    "    target_df.set_index(source_key, inplace=True)\n",
    "    source_df.set_index(source_key, inplace=True)\n",
    "\n",
    "    # 2. Update Existing Rows in the Target with New Values from the Source\n",
    "    target_df.update(source_df)  # Update rows with matching indices\n",
    "    \n",
    "    # 3. Add New Rows from the Source to the Target \n",
    "    df_upserted = target_df.combine_first(source_df).sort_index()\n",
    "\n",
    "    # 4. Set the index back to its default (not a column in the dataframe)\n",
    "    df_upserted.reset_index(level=None, inplace=True)\n",
    "\n",
    "    # 5. Drop the in-memory primary key of the Target.\n",
    "    df_upserted.drop(target_key, axis=1, inplace=True)\n",
    "    \n",
    "    return df_upserted[columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64fde048-4f90-45b7-9378-c3cd609fa7ed",
   "metadata": {},
   "source": [
    "### 2.0. Use Python and Pandas Dataframes to Apply Upsert Logic\n",
    "This approach works well for small to mid-sized tables as data must first be marshalled from both the source and destination (target) database management servers to the Python client, and the **upserted** result must then marshalled back to the target database management server to persist the changes.\n",
    "\n",
    "#### 2.1. Execute Some Changes to the Source Database **northwind**\n",
    "Before proceding any further, you **must** first execute the SQL Script named <a href=\"https://github.com/JTupitza-UVA/DS-2002/blob/main/02-Python/data/Lab_03b_Modify_Data.sql\"><b>Lab_03b_Modify_Data.sql</b></a> located in the **/02-Python/data** folder. This script **inserts** new rows, and **updates** existing rows in the dimension tables: dim_customers, dim_employees, dim_products, and dim_shippers.\n",
    "\n",
    "#### 2.2. Extract Data from the Transaction Processing (source) Database Tables\n",
    "First, we will fetch data for each dimension table (e.g., customers, employees, products, shippers) from the original **northwind** (source) database using the **get_dataframe()** function. Any changes (i.e., newly added rows, and updates made to existing rows) can be detected.\n",
    "\n",
    "For optimal performance these changes can be incrementally extracted either from **Change Data Capture (CDC)** tables when the source RDBMS supports that feature, or by filtering rows using either a **last_modified** datetime column or an **is_current** boolean (a.k.a., flag) column that can be included in the schema design of those source tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a93500a-5801-4381-a31f-f674f6b61caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Get a connection object to the source server\n",
    "src_connection = get_mysql_connection(user_id, pwd, host_name, src_dbname)\n",
    "\n",
    "# 2. Extract a Pandas DataFrame containing the most recent version of the source data.\n",
    "sql_customers = \"SELECT * FROM northwind.customers;\"\n",
    "df_customers = get_dataframe(src_connection, sql_customers)\n",
    "\n",
    "# 3. Enumerate the names of each column you wish to remove (drop) from the Pandas DataFrame\n",
    "drop_cols = ['email_address','home_phone','mobile_phone','web_page','notes','attachments']\n",
    "df_customers.drop(drop_cols, axis=1, inplace=True)\n",
    "\n",
    "# 4. Rename the 'id' column to reflect the entity represented by the table\n",
    "df_customers.rename(columns={\"id\" : \"customer_id\"}, inplace=True)\n",
    "df_customers.tail(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d89c29bf-c740-4e9e-b114-b24d51c3208a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Extract a Pandas DataFrame containing the most recent version of the source data from the \"employees\" table in the Northwind database.\n",
    "\n",
    "#TODO: Drop the following columns from the 'df_employees' Dataframe: mobile_phone, notes, and attachments.\n",
    "\n",
    "#TODO: Rename the 'id' column to 'employee_id'\n",
    "\n",
    "df_employees.tail(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ede905-b3c0-4874-9f0c-dba76fd9c8aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Extract a Pandas DataFrame containing the most recent version of the source data from the \"products\" table in the Northwind database.\n",
    "\n",
    "#TODO: Drop the following columns from the 'df_products' Dataframe: supplier_ids, description, and attachments.\n",
    "\n",
    "#TODO: Rename the 'id' column to 'product_id'\n",
    "\n",
    "df_products.tail(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b8f1d27-264d-419f-972b-a73ec42beddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Extract a Pandas DataFrame containing the most recent version of the source data from the \"shippers\" table in the Northwind database.\n",
    "\n",
    "#TODO: Drop the following columns from the 'df_shippers' Dataframe:\n",
    "     # last_name, first_name, email_address, job_title, business_phone, home_phone, mobile_phone, fax_number, web_page, notes, and attachments.\n",
    "\n",
    "#TODO: Rename the 'id' column to 'shipper_id'\n",
    "\n",
    "df_shippers.tail(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be18d492-fe78-42df-9917-67473c0471b0",
   "metadata": {},
   "source": [
    "##### 1.4. Extract Data from the Data Warehouse (target) Tables.\n",
    "The next step is to retrieve the current state of the **target** data warehouse. This can be used to detect the delta (difference) between the **source** (northwind) and destination (northwind_dw2) database's tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08218417-ecaa-4280-ae41-32b94a3048f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_connection = get_mysql_connection(user_id, pwd, host_name, src_dbname)\n",
    "\n",
    "sql_dim_customers = \"SELECT * FROM northwind_dw2.dim_customers;\"\n",
    "df_dim_customers = get_dataframe(src_connection, sql_dim_customers)\n",
    "df_dim_customers.tail(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c78a9c-baf6-4c8b-9de6-613387e9c6f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Fetch data from the 'dim_employees' table in the northwind_dw2 data warehouse database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17885cc0-360f-443b-9cf6-17863701b0bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Fetch data from the 'dim_products' table in the northwind_dw2 data warehouse database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eecf83d1-8f8b-49ef-b310-f87f0238d7ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Fetch data from the 'dim_shippers' table in the northwind_dw2 data warehouse database."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "312fe403-e318-4dee-9496-11a4c1f60bf3",
   "metadata": {},
   "source": [
    "##### 1.3. Apply Upsert Logic\n",
    "Calling the **upsert_dataframes()** function returns a dataframe containing the product of a **Merge** being applied to the **target** dimension tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf22a4e3-4b37-4771-9a8d-914ef9767187",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1). List the preferred column order for the final Customers dimension table.\n",
    "ordered_cols=['customer_id', 'company', 'last_name', 'first_name', 'job_title', 'business_phone'\n",
    "              , 'fax_number', 'address', 'city', 'state_province', 'zip_postal_code', 'country_region']\n",
    "\n",
    "# 2). Call the upsert_dataframes function passing the source dataframe, business_key, target dataframe, surrogate primary key, and ordered columns list\n",
    "df_dim_customers = upsert_dataframes(df_customers, \"customer_id\", df_dim_customers, \"customer_key\", ordered_cols)\n",
    "df_dim_customers.tail(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b773de-c262-4972-9f05-3a7757d4f4a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1). List the preferred column order for the final Employees dimension table.\n",
    "\n",
    "# 2). Call the upsert_dataframes function passing the source dataframe, business_key, target dataframe, surrogate primary key, and ordered columns list\n",
    "\n",
    "df_dim_employees.tail(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e166467-2475-49be-8f1a-dd5934564e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1). List the preferred column order for the final Products dimension table.\n",
    "\n",
    "# 2). Call the upsert_dataframes function passing the source dataframe, business_key, target dataframe, surrogate primary key, and ordered columns list\n",
    "\n",
    "df_dim_products.tail(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa7252e5-04b6-4ed5-a5f8-c4e199953f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1). List the preferred column order for the final Shippersyees dimension table.\n",
    "\n",
    "# 2). Call the upsert_dataframes function passing the source dataframe, business_key, target dataframe, surrogate primary key, and ordered columns list\n",
    "\n",
    "df_dim_shippers.tail(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42b96957-aff1-406b-a36a-7a1654c02c19",
   "metadata": {},
   "source": [
    "##### 1.4. Load the newly UPSERTED dataframes into the Data Warehouse\n",
    "Calling the **set_dataframe()** function uses the **Upserted** dataframes to created updated versions of the dimension tables in the **northwind_dw2** (target) data warehouse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba596c1-de5f-4430-ae19-eb4cbeb61730",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1). Call the get_mysql_connection() function to create a connection to the target (northwind_dw2) database\n",
    "dst_connection = get_mysql_connection(user_id, pwd, host_name, dst_dbname)\n",
    "\n",
    "# 2). Call the set_dataframe function passing the connection object, upserted dataframe, and the names of the dimension table, primary key, and \"insert\"\n",
    "set_dataframe(dst_connection, df_dim_customers, \"dim_customers\", \"customer_key\", \"insert\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98d560d-eef5-4562-9c9f-52112312c2a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1). Call the get_mysql_connection() function to create a connection to the target (northwind_dw2) database\n",
    "dst_connection = get_mysql_connection(user_id, pwd, host_name, dst_dbname)\n",
    "\n",
    "# 2). Call the set_dataframe function passing the connection object, upserted dataframe, and the names of the dimension table, primary key, and \"insert\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf86093-65cc-4756-aea2-d3d7b32afb6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1). Call the get_mysql_connection() function to create a connection to the target (northwind_dw2) database\n",
    "dst_connection = get_mysql_connection(user_id, pwd, host_name, dst_dbname)\n",
    "\n",
    "# 2). Call the set_dataframe function passing the connection object, upserted dataframe, and the names of the dimension table, primary key, and \"insert\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "095cf5f1-43c9-4be2-bdd5-5c6ae91b6542",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1). Call the get_mysql_connection() function to create a connection to the target (northwind_dw2) database\n",
    "dst_connection = get_mysql_connection(user_id, pwd, host_name, dst_dbname)\n",
    "\n",
    "# 2). Call the set_dataframe function passing the connection object, upserted dataframe, and the names of the dimension table, primary key, and \"insert\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f6e775-bd94-40c6-92e8-bce602347db9",
   "metadata": {},
   "source": [
    "##### 1.5. Verify (Unit Test) Upsert Results\n",
    "Finally, we can re-query the state of each dimension table to verify that the new changes now exist in each dimension table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd8187d-3d05-4e3e-b6ad-a90b0559da20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1). Call the get_mysql_connection() function to create a connection to the target (northwind_dw2) database\n",
    "src_connection = get_mysql_connection(user_id, pwd, host_name, src_dbname)\n",
    "\n",
    "# 2). Call the get_dataframe function to the entire contents of the 'dim_customers' table.\n",
    "sql_dim_customers = \"SELECT * FROM northwind_dw2.dim_customers;\"\n",
    "df_dim_customers = get_dataframe(src_connection, sql_dim_customers)\n",
    "df_dim_customers.tail(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed1790be-732d-40e7-9f37-8623ccd65dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Fetch data from the 'dim_employees' table in the northwind_dw2 data warehouse database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab1bb3a0-7c28-4898-ad6a-8c912a6784ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Fetch data from the 'dim_products' table in the northwind_dw2 data warehouse database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5483f565-8ac5-4181-a60a-de03fffcfdd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Fetch data from the 'dim_shippers' table in the northwind_dw2 data warehouse database."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (3.12.7-env)",
   "language": "python",
   "name": "3.12.7-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
